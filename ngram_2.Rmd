---
title: "N-Gram Intrusion Detection (Part 2)"
author: "Kexuan Zou"
date: "April 19, 2018"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
library(reticulate)
knitr::knit_engines$set(python = reticulate::eng_python)
```

[Back to Part 1](https://klauschow.me/research/ngram_1.html)

## Choosing Machine Learning Algorithms
From `prim.csv`, we may load the software dataset into an numpy array, and then split that into a training and test set. Use **Principle Component Analysis (PCA)** to visulize the dataset. Principle Component Analysis uses an orthogonal transformation to convert multi-dimensional feature vectors into smaller, linearly-independent vectors. We can then choose what machine learning algorithm to apply based on the result of PCA. Since we are dealing with a binary classification {0: benign; 1: malicious}, and dimension for features is high (45), we can first try **Support Vector Machine (SVM)**. Scikit-learn implements linear SVM that is particularly efficient in solving high dimension, binary classification problem like this. To understand why this is the case, we can first superimpose the support vectors obtained from the SVM onto the training set:

```{python}
# external reference: http://www.dummies.com/programming/big-data/data-science/how-to-visualize-the-classifier-in-an-svm-supervised-learning-model/
import numpy as np
import numpy as np
import pylab as pl
from sklearn import svm
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split

dataset = np.loadtxt(open("prim.csv", "rb"), delimiter=",")
train_x, test_x, train_y, test_y = train_test_split(dataset[:,:-1], dataset[:,-1], test_size=.2)

model_svm = svm.SVC(kernel="linear")
model_svm.fit(train_x, train_y)
pred_svm = model_svm.predict(test_x)
cm_svm = confusion_matrix(test_y, pred_svm)
print(cm_svm)
score_svm = accuracy_score(test_y, pred_svm)
print(score_svm)

pca = PCA(n_components=2).fit(train_x)
pca_2d = pca.transform(train_x)
svs_2d = pca.transform(model_svm.support_vectors_)

for i in range(0, pca_2d.shape[0]):
    if train_y[i] == 0:
        c1 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='g', marker='o')
    elif train_y[i] == 1:
        c2 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='b', marker='*')
for i in range(0, svs_2d.shape[0]):
    c3 = pl.scatter(svs_2d[i,0],svs_2d[i,1],c='r', marker='x')
pl.legend([c1, c2, c3], ["benign", "malicious", "support vectors"])
pl.title("PCA Analysis of the Software Dataset with SVM")
pl.show()
```

It can be shown from the result that the classifier can accurately predict a malware, but in most cases falsely predict a benign software as a malware as well.

[Back to Part 1](https://klauschow.me/research/ngram_1.html)
